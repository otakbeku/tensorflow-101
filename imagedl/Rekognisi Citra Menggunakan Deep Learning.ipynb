{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rekognisi Citra Menggunakan Deep Learning\n",
    "\n",
    "Materi yang diajarkan pada *notebook* ini adalah:\n",
    "1. *Fully-connected Layer*\n",
    "2. *Convolutional Layer*\n",
    "3. *Convolutional Neural Networks*\n",
    "4. *Pooling Layer*\n",
    "5. Implementasi *Deep Learning* pada rekognisi citra\n",
    "6. Implementasi rekognisis citra dengan keras\n",
    "\n",
    "## *Fully-connected Layer*\n",
    "+ Terdiri dari neuron-neuron yang terhubung ke seluruh input, seperti dalam neural networks biasa\n",
    "+ Implementasi dengan menggunakan CIFAR-10\n",
    "    + Citra 32x32x3 diubah menjadi vektor 1 dimensi dengan ukuran 3072\n",
    "    + Output yang diharapkan berukuran 10 -> 10 kelas dari CIFAR-10\n",
    "    + Jumlah parameter yang diperlukan 10 x 3072\n",
    "+ Jumlah *dot procut* adalah satu\n",
    "\n",
    "![fcl](Asset/fcl-1.png)\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "## Convolutional Layer\n",
    "\n",
    "+ Mengubah bentuk dimensi dari citra tanpa menghilangkan kedalaman dari input\n",
    "+ Menggunakan operasi *dot product* antara citra input dengan kernel yang digeser secara berkala\n",
    "+ Yang penting dalam konvolusi: Ukuran kernel, besaran perpindahan atau *stride*, *spatial extent*, dan *zero padding*\n",
    "+ Layer ini menerima:\n",
    "    + input berukuran $W_1\\times H_1 \\times D_1$ (**ket: W = Lebar, H = Tinggi, D = kedalaman**)\n",
    "    + Parameter: Number of filters K, spatial extent F, stride S, zero padding P\n",
    "    + Menghasilkan $W_2\\times H_2 \\times D_2$ dimana: \n",
    "        + $W_2 = (W_1 - F + 2P)/S+1$\n",
    "        + $H_2 = (H_1 - F + 2P)/S+1$\n",
    "        + $D_2 = K$\n",
    "![convolution](Asset/convl-1.png)\n",
    "+ Hasil dari konvolusi berupa *map* aktivasi. Konvolusi dilakukan diseluruh bagian citra\n",
    "+ Laman interaktif untuk Konvolusi [link](http://cs231n.github.io/convolutional-networks/)\n",
    "![convolution](Asset/convl-2.png)\n",
    "![convolution](Asset/convl-3.png)\n",
    "+ Jika ada 6 filter, maka akan menghasilkan 6 *map* aktivasi yang berbeda\n",
    "+ Kita bisa menggabungkan hasil konvosuli sebagai citra baru dengan ukuran $28\\times28\\times6$\n",
    "![convolution](Asset/convl-4.png)\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "##  Convolutional Neural Network\n",
    "\n",
    "+ Akrab disebut dengan CNN adalah rangkaian Convolutional Layer yang diselingi dengan fungsi aktivasi\n",
    "\n",
    "![cnn](Asset/cnn-1.png)\n",
    "![cnn](Asset/cnn-2.png)\n",
    "\n",
    "## Pooling Layer\n",
    "\n",
    "+ Membat representasi lebih kecil dan lebih mudah diatur\n",
    "+ Beroperasi di atas setiap map aktivasi secara independen\n",
    "![pool](Asset/pool-1.png)\n",
    "\n",
    "### Max Pooling\n",
    "\n",
    "+ Filter yang mengambil nilai terbesar dari suatu *patch* (sub-bagian)\n",
    "![maxpool](Asset/maxpool-1.png)\n",
    "\n",
    "## Implementasi dengan keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/250\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 1.9400 - acc: 0.2778 - val_loss: 1.7025 - val_acc: 0.3858\n",
      "Epoch 2/250\n",
      "50000/50000 [==============================] - 39s 787us/step - loss: 1.6173 - acc: 0.4057 - val_loss: 1.5094 - val_acc: 0.4470\n",
      "Epoch 3/250\n",
      "50000/50000 [==============================] - 39s 789us/step - loss: 1.4899 - acc: 0.4547 - val_loss: 1.4030 - val_acc: 0.5017\n",
      "Epoch 4/250\n",
      "50000/50000 [==============================] - 39s 788us/step - loss: 1.4101 - acc: 0.4884 - val_loss: 1.3315 - val_acc: 0.5148\n",
      "Epoch 5/250\n",
      "50000/50000 [==============================] - 41s 814us/step - loss: 1.3464 - acc: 0.5139 - val_loss: 1.2613 - val_acc: 0.5481\n",
      "Epoch 6/250\n",
      "50000/50000 [==============================] - 41s 812us/step - loss: 1.2952 - acc: 0.5362 - val_loss: 1.2075 - val_acc: 0.5711\n",
      "Epoch 7/250\n",
      "50000/50000 [==============================] - 40s 805us/step - loss: 1.2530 - acc: 0.5525 - val_loss: 1.1889 - val_acc: 0.5723\n",
      "Epoch 8/250\n",
      "50000/50000 [==============================] - 41s 820us/step - loss: 1.2140 - acc: 0.5677 - val_loss: 1.1575 - val_acc: 0.5963\n",
      "Epoch 9/250\n",
      "50000/50000 [==============================] - 40s 809us/step - loss: 1.1789 - acc: 0.5833 - val_loss: 1.1144 - val_acc: 0.6141\n",
      "Epoch 10/250\n",
      "50000/50000 [==============================] - 41s 817us/step - loss: 1.1464 - acc: 0.5952 - val_loss: 1.0873 - val_acc: 0.6173\n",
      "Epoch 11/250\n",
      "50000/50000 [==============================] - 40s 804us/step - loss: 1.1196 - acc: 0.6037 - val_loss: 1.0736 - val_acc: 0.6196\n",
      "Epoch 12/250\n",
      "50000/50000 [==============================] - 42s 838us/step - loss: 1.0969 - acc: 0.6130 - val_loss: 1.0574 - val_acc: 0.6270\n",
      "Epoch 13/250\n",
      "50000/50000 [==============================] - 43s 865us/step - loss: 1.0646 - acc: 0.6243 - val_loss: 1.0212 - val_acc: 0.6453\n",
      "Epoch 14/250\n",
      "50000/50000 [==============================] - 46s 918us/step - loss: 1.0426 - acc: 0.6329 - val_loss: 0.9943 - val_acc: 0.6540\n",
      "Epoch 15/250\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 1.0206 - acc: 0.6414 - val_loss: 0.9796 - val_acc: 0.6575\n",
      "Epoch 16/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.0008 - acc: 0.6483 - val_loss: 0.9707 - val_acc: 0.6636\n",
      "Epoch 17/250\n",
      "50000/50000 [==============================] - 44s 872us/step - loss: 0.9786 - acc: 0.6567 - val_loss: 0.9316 - val_acc: 0.6770\n",
      "Epoch 18/250\n",
      "50000/50000 [==============================] - 42s 839us/step - loss: 0.9631 - acc: 0.6612 - val_loss: 0.9142 - val_acc: 0.6825\n",
      "Epoch 19/250\n",
      "50000/50000 [==============================] - 41s 819us/step - loss: 0.9480 - acc: 0.6681 - val_loss: 0.9241 - val_acc: 0.6777\n",
      "Epoch 20/250\n",
      "50000/50000 [==============================] - 40s 802us/step - loss: 0.9233 - acc: 0.6754 - val_loss: 0.8833 - val_acc: 0.6959\n",
      "Epoch 21/250\n",
      "50000/50000 [==============================] - 40s 801us/step - loss: 0.9065 - acc: 0.6823 - val_loss: 0.8727 - val_acc: 0.6988\n",
      "Epoch 22/250\n",
      "50000/50000 [==============================] - 45s 901us/step - loss: 0.8892 - acc: 0.6895 - val_loss: 0.8779 - val_acc: 0.6968\n",
      "Epoch 23/250\n",
      "50000/50000 [==============================] - 46s 914us/step - loss: 0.8745 - acc: 0.6937 - val_loss: 0.8523 - val_acc: 0.7023\n",
      "Epoch 24/250\n",
      "50000/50000 [==============================] - 42s 849us/step - loss: 0.8624 - acc: 0.6986 - val_loss: 0.8313 - val_acc: 0.7114\n",
      "Epoch 25/250\n",
      "50000/50000 [==============================] - 43s 865us/step - loss: 0.8429 - acc: 0.7053 - val_loss: 0.8410 - val_acc: 0.7093\n",
      "Epoch 26/250\n",
      "50000/50000 [==============================] - 41s 824us/step - loss: 0.8298 - acc: 0.7082 - val_loss: 0.8240 - val_acc: 0.7133\n",
      "Epoch 27/250\n",
      "50000/50000 [==============================] - 42s 845us/step - loss: 0.8194 - acc: 0.7088 - val_loss: 0.8083 - val_acc: 0.7182\n",
      "Epoch 28/250\n",
      "50000/50000 [==============================] - 41s 827us/step - loss: 0.8040 - acc: 0.7188 - val_loss: 0.7919 - val_acc: 0.7243\n",
      "Epoch 29/250\n",
      "50000/50000 [==============================] - 43s 857us/step - loss: 0.7883 - acc: 0.7241 - val_loss: 0.7900 - val_acc: 0.7265\n",
      "Epoch 30/250\n",
      "50000/50000 [==============================] - 42s 842us/step - loss: 0.7747 - acc: 0.7297 - val_loss: 0.7663 - val_acc: 0.7335\n",
      "Epoch 31/250\n",
      "50000/50000 [==============================] - 43s 857us/step - loss: 0.7661 - acc: 0.7329 - val_loss: 0.7631 - val_acc: 0.7357\n",
      "Epoch 32/250\n",
      "50000/50000 [==============================] - 42s 844us/step - loss: 0.7538 - acc: 0.7381 - val_loss: 0.7717 - val_acc: 0.7351\n",
      "Epoch 33/250\n",
      "50000/50000 [==============================] - 40s 809us/step - loss: 0.7436 - acc: 0.7391 - val_loss: 0.7451 - val_acc: 0.7412\n",
      "Epoch 34/250\n",
      "50000/50000 [==============================] - 41s 814us/step - loss: 0.7285 - acc: 0.7461 - val_loss: 0.7338 - val_acc: 0.7476\n",
      "Epoch 35/250\n",
      "50000/50000 [==============================] - 41s 821us/step - loss: 0.7178 - acc: 0.7483 - val_loss: 0.7425 - val_acc: 0.7423716\n",
      "Epoch 36/250\n",
      "50000/50000 [==============================] - 41s 818us/step - loss: 0.7095 - acc: 0.7524 - val_loss: 0.7271 - val_acc: 0.7468\n",
      "Epoch 37/250\n",
      "50000/50000 [==============================] - 40s 795us/step - loss: 0.6982 - acc: 0.7556 - val_loss: 0.7255 - val_acc: 0.7495\n",
      "Epoch 38/250\n",
      "50000/50000 [==============================] - 41s 815us/step - loss: 0.6851 - acc: 0.7624 - val_loss: 0.7149 - val_acc: 0.7535\n",
      "Epoch 39/250\n",
      "50000/50000 [==============================] - 47s 933us/step - loss: 0.6824 - acc: 0.7618 - val_loss: 0.6996 - val_acc: 0.7591 2s - los\n",
      "Epoch 40/250\n",
      "50000/50000 [==============================] - 44s 876us/step - loss: 0.6713 - acc: 0.7646 - val_loss: 0.6989 - val_acc: 0.7567\n",
      "Epoch 41/250\n",
      "50000/50000 [==============================] - 48s 954us/step - loss: 0.6620 - acc: 0.7690 - val_loss: 0.6913 - val_acc: 0.7601\n",
      "Epoch 42/250\n",
      "50000/50000 [==============================] - 48s 950us/step - loss: 0.6489 - acc: 0.7739 - val_loss: 0.7008 - val_acc: 0.7571\n",
      "Epoch 43/250\n",
      "50000/50000 [==============================] - 43s 868us/step - loss: 0.6427 - acc: 0.7759 - val_loss: 0.6796 - val_acc: 0.7667\n",
      "Epoch 44/250\n",
      "50000/50000 [==============================] - 44s 871us/step - loss: 0.6355 - acc: 0.7779 - val_loss: 0.6780 - val_acc: 0.7666\n",
      "Epoch 45/250\n",
      "50000/50000 [==============================] - 44s 874us/step - loss: 0.6248 - acc: 0.7810 - val_loss: 0.6755 - val_acc: 0.7640\n",
      "Epoch 46/250\n",
      "50000/50000 [==============================] - 45s 901us/step - loss: 0.6199 - acc: 0.7834 - val_loss: 0.6701 - val_acc: 0.7684\n",
      "Epoch 47/250\n",
      "50000/50000 [==============================] - 45s 901us/step - loss: 0.6101 - acc: 0.7891 - val_loss: 0.6690 - val_acc: 0.7682\n",
      "Epoch 48/250\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.6004 - acc: 0.7887 - val_loss: 0.6616 - val_acc: 0.7736\n",
      "Epoch 49/250\n",
      "50000/50000 [==============================] - 45s 904us/step - loss: 0.5967 - acc: 0.7915 - val_loss: 0.6587 - val_acc: 0.7735\n",
      "Epoch 50/250\n",
      "50000/50000 [==============================] - 45s 896us/step - loss: 0.5884 - acc: 0.7943 - val_loss: 0.6491 - val_acc: 0.7756\n",
      "Epoch 51/250\n",
      "50000/50000 [==============================] - 46s 917us/step - loss: 0.5814 - acc: 0.7970 - val_loss: 0.6629 - val_acc: 0.7721\n",
      "Epoch 52/250\n",
      "50000/50000 [==============================] - 47s 934us/step - loss: 0.5708 - acc: 0.8008 - val_loss: 0.6442 - val_acc: 0.7766\n",
      "Epoch 53/250\n",
      "50000/50000 [==============================] - 44s 875us/step - loss: 0.5626 - acc: 0.8027 - val_loss: 0.6687 - val_acc: 0.7725\n",
      "Epoch 54/250\n",
      "50000/50000 [==============================] - 46s 925us/step - loss: 0.5588 - acc: 0.8043 - val_loss: 0.6408 - val_acc: 0.7771\n",
      "Epoch 55/250\n",
      "50000/50000 [==============================] - 45s 893us/step - loss: 0.5481 - acc: 0.8086 - val_loss: 0.6390 - val_acc: 0.7792\n",
      "Epoch 56/250\n",
      "50000/50000 [==============================] - 44s 889us/step - loss: 0.5438 - acc: 0.8079 - val_loss: 0.6334 - val_acc: 0.7809\n",
      "Epoch 57/250\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.5380 - acc: 0.8102 - val_loss: 0.6391 - val_acc: 0.7808\n",
      "Epoch 58/250\n",
      "50000/50000 [==============================] - 48s 964us/step - loss: 0.5316 - acc: 0.8138 - val_loss: 0.6325 - val_acc: 0.7844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/250\n",
      "50000/50000 [==============================] - 44s 873us/step - loss: 0.5213 - acc: 0.8177 - val_loss: 0.6303 - val_acc: 0.7852\n",
      "Epoch 60/250\n",
      "50000/50000 [==============================] - 44s 874us/step - loss: 0.5153 - acc: 0.8198 - val_loss: 0.6310 - val_acc: 0.7836\n",
      "Epoch 61/250\n",
      "50000/50000 [==============================] - 43s 854us/step - loss: 0.5099 - acc: 0.8211 - val_loss: 0.6246 - val_acc: 0.7852\n",
      "Epoch 62/250\n",
      "50000/50000 [==============================] - 43s 853us/step - loss: 0.5061 - acc: 0.8240 - val_loss: 0.6146 - val_acc: 0.7884\n",
      "Epoch 63/250\n",
      "50000/50000 [==============================] - 45s 894us/step - loss: 0.5022 - acc: 0.8240 - val_loss: 0.6194 - val_acc: 0.7886\n",
      "Epoch 64/250\n",
      "50000/50000 [==============================] - 42s 847us/step - loss: 0.4965 - acc: 0.8249 - val_loss: 0.6096 - val_acc: 0.7896\n",
      "Epoch 65/250\n",
      "50000/50000 [==============================] - 44s 890us/step - loss: 0.4878 - acc: 0.8286 - val_loss: 0.6155 - val_acc: 0.7923\n",
      "Epoch 66/250\n",
      "50000/50000 [==============================] - 43s 851us/step - loss: 0.4820 - acc: 0.8301 - val_loss: 0.6086 - val_acc: 0.7911\n",
      "Epoch 67/250\n",
      "50000/50000 [==============================] - 43s 851us/step - loss: 0.4760 - acc: 0.8313 - val_loss: 0.6070 - val_acc: 0.7941\n",
      "Epoch 68/250\n",
      "50000/50000 [==============================] - 44s 871us/step - loss: 0.4754 - acc: 0.8326 - val_loss: 0.6167 - val_acc: 0.7880\n",
      "Epoch 69/250\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.4602 - acc: 0.8375 - val_loss: 0.6205 - val_acc: 0.7904\n",
      "Epoch 70/250\n",
      "50000/50000 [==============================] - 47s 945us/step - loss: 0.4604 - acc: 0.8369 - val_loss: 0.6085 - val_acc: 0.7913\n",
      "10000/10000 [==============================] - 6s 551us/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute '3f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f1a885de2816>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss {.3f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy {.3f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute '3f'"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=Adam(lr=0.0001, decay=1e-6),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train/255.0, to_categorical(Y_train),\n",
    "         batch_size=128,\n",
    "         shuffle=True,\n",
    "         epochs=250,\n",
    "         validation_data=(X_test/255.0, to_categorical(Y_test)),\n",
    "         callbacks=[EarlyStopping(min_delta=0.001, patience=3)])\n",
    "\n",
    "scores = model.evaluate(X_test/255.0, to_categorical(Y_test))\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "print('Loss {}'.format(scores[0]))\n",
    "print('Accuracy {}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
